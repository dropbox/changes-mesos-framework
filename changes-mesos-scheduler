#!/usr/bin/env python

from __future__ import absolute_import, print_function

import argparse
import json
import logging
import os
import signal
import sys
import time
import urllib2

from time import sleep
from threading import Event
from uuid import uuid4

try:
    from mesos.native import MesosSchedulerDriver
    from mesos.interface import Scheduler
    from mesos.interface import mesos_pb2
except ImportError:
    from mesos import MesosSchedulerDriver, Scheduler
    import mesos_pb2


# Configuration should contain the file 'blacklist' which
# is a line-separated lists of hosts to blacklist.
#
# NOTE: inside ec2, hostnames look like
# ip-*-*-*-*.region.compute.internal
DEFAULT_CONFIG_DIR='/etc/changes-mesos-scheduler'


def install_sentry_logger():
    try:
        import raven
    except ImportError:
        logging.warning('Unable to find raven library. Sentry integration disabled.')
        return

    from raven.conf import setup_logging
    from raven.handlers.logging import SentryHandler

    client = raven.Client()
    handler = SentryHandler(client, level=logging.WARN)
    setup_logging(handler)


class ChangesScheduler(Scheduler):
    def __init__(self, executor, api_url, config_dir):
        self.executor = executor
        self.api_url = api_url
        self.taskJobStepMapping = {}
        self.tasksLaunched = 0
        self.tasksFinished = 0
        self.shuttingDown = Event()
        self.blacklist_path = os.path.join(config_dir, 'blacklist')
        self._refresh_blacklist()

    def registered(self, driver, frameworkId, masterInfo):
        """
          Invoked when the scheduler successfully registers with a Mesos master.
          It is called with the frameworkId, a unique ID generated by the
          master, and the masterInfo which is information about the master
          itself.
        """
        logging.info("Registered with framework ID %s", frameworkId.value)

    def reregistered(self, driver, masterInfo):
        """
          Invoked when the scheduler re-registers with a newly elected Mesos
          master.  This is only called when the scheduler has previously been
          registered.  masterInfo contains information about the newly elected
          master.
        """
        logging.info("Re-Registered with new master")

    def disconnected(self, driver):
        """
          Invoked when the scheduler becomes disconnected from the master, e.g.
          the master fails and another is taking over.
        """
        logging.info("Disconnected from master")

    def _should_refresh_blacklist(self):
        """
          Detects if we need to reload the blacklist configuration
          based on the timestamps of the blacklist path file.
        """
        return os.path.getmtime(self.blacklist_path) > self.blacklist_time

    def _refresh_blacklist(self):
        """
          Reload the blacklist by reading blacklist_path and adding
          the hostnames to the blacklist set, one per line. Note that
          the "blank" hostname will get added if there are any blank
          lines because we don't sort them out but this shouldn't
          be an issue.
        """
        logging.info('Refreshing blacklist')
        self.blacklist_time = int(time.time())
        with open(self.blacklist_path) as file:
            self.blacklist = set([s.strip() for s in file.readlines() if not s.startswith('#')])

    @staticmethod
    def _decode_typed_field(pb):
        field_type = pb.type
        if field_type == 0:  # Scalar
            return pb.scalar.value
        elif field_type == 1:  # Ranges
            return [{"begin": ra.begin, "end": ra.end} for ra in pb.ranges.range]
        elif field_type == 2:  # Set
            return pb.set.item
        elif field_type == 3:  # Text
            return pb.text.value
        else:
            raise Exception("Unknown field type: %s", field_type)

    @staticmethod
    def _decode_attribute(attr_pb):
        return {attr_pb.name: ChangesScheduler._decode_typed_field(attr_pb)}

    @staticmethod
    def _decode_resource(resource_pb):
        return (resource_pb.name, ChangesScheduler._decode_typed_field(resource_pb))

    @property
    def activeTasks(self):
        return self.tasksFinished - self.tasksLaunched

    def resourceOffers(self, driver, offers):
        """
          Invoked when resources have been offered to this framework. A single
          offer will only contain resources from a single slave.  Resources
          associated with an offer will not be re-offered to _this_ framework
          until either (a) this framework has rejected those resources (see
          SchedulerDriver.launchTasks) or (b) those resources have been
          rescinded (see Scheduler.offerRescinded).  Note that resources may be
          concurrently offered to more than one framework at a time (depending
          on the allocator being used).  In that case, the first framework to
          launch tasks using those resources will be able to use them while the
          other frameworks will have those resources rescinded (or if a
          framework has already launched tasks with those resources then those
          tasks will fail with a TASK_LOST status and a message saying as much).
        """
        logging.info("Got %d resource offers", len(offers))

        if self._should_refresh_blacklist():
            self._refresh_blacklist()

        for offer in offers:
            if self.shuttingDown.is_set():
                logging.info("Shutting down, declining offer: %s", offer.id)
                driver.declineOffer(offer.id)
                continue

            if offer.hostname in self.blacklist:
                logging.info("Declining offer from blacklisted hostname: %s", offer.hostname)
                driver.declineOffer(offer.id)
                continue

            # protobuf -> dict
            info = {
                "attributes": [ChangesScheduler._decode_attribute(a) for a in offer.attributes],
                "executor_ids": [ei.value for ei in offer.executor_ids],
                "framework_id": offer.framework_id.value,
                "hostname": offer.hostname,
                "id": offer.id.value,
                "resources": {name: value
                              for (name, value)
                              in [ChangesScheduler._decode_resource(r) for r in offer.resources]},
                "slave_id": offer.slave_id.value,
            }
            logging.debug("Offer: %s", json.dumps(info, sort_keys=True, indent=2, separators=(',', ': ')))

            # hit service with our offer
            try:
                req = urllib2.Request(
                    self.api_url + "/jobsteps/allocate/", json.dumps(info),
                    {'Content-Type': 'application/json'})
                tasks_to_run = json.loads(urllib2.urlopen(req).read())
            except Exception:
                driver.declineOffer(offer.id)
                logging.exception("Error POSTing offer to service at %s", req.get_full_url())
                continue

            if len(tasks_to_run) == 0:
                logging.info("No tasks to run, declining offer: %s", offer.id)
                driver.declineOffer(offer.id)
                continue

            tasks = []
            for task_to_run in tasks_to_run:
                tid = uuid4().hex
                self.tasksLaunched += 1

                logging.info("Accepting offer on %s to start task %s", offer.hostname, tid)

                task = mesos_pb2.TaskInfo()
                task.name = "{} {}".format(
                    task_to_run['project']['slug'],
                    task_to_run['id'],
                )
                task.task_id.value = str(tid)
                task.slave_id.value = offer.slave_id.value

                cmd = task_to_run["cmd"]

                task.command.value = cmd
                logging.debug("Scheduling cmd: %s", cmd)

                # task.executor.MergeFrom(self.executor)
                # task.executor.data = task_to_run["cmd"].encode("utf-8")

                cpus = task.resources.add()
                cpus.name = "cpus"
                cpus.type = mesos_pb2.Value.SCALAR
                cpus.scalar.value = task_to_run["resources"]["cpus"]

                mem = task.resources.add()
                mem.name = "mem"
                mem.type = mesos_pb2.Value.SCALAR
                mem.scalar.value = task_to_run["resources"]["mem"]

                tasks.append(task)

                self.taskJobStepMapping[task.task_id.value] = task_to_run['id']
            driver.launchTasks(offer.id, tasks)

    def offerRescinded(self, driver, offerId):
        """
          Invoked when an offer is no longer valid (e.g., the slave was lost or
          another framework used resources in the offer.) If for whatever reason
          an offer is never rescinded (e.g., dropped message, failing over
          framework, etc.), a framwork that attempts to launch tasks using an
          invalid offer will receive TASK_LOST status updats for those tasks
          (see Scheduler.resourceOffers).
        """
        logging.info("Offer rescinded: %s", offerId.value)

    def statusUpdate(self, driver, status):
        """
          Invoked when the status of a task has changed (e.g., a slave is lost
          and so the task is lost, a task finishes and an executor sends a
          status update saying so, etc.) Note that returning from this callback
          acknowledges receipt of this status update.  If for whatever reason
          the scheduler aborts during this callback (or the process exits)
          another status update will be delivered.  Note, however, that this is
          currently not true if the slave sending the status update is lost or
          fails during that time.
        """

        states = {
            0: "starting",
            1: "running",
            2: "finished",  # terminal
            3: "failed",  # terminal
            4: "killed",  # terminal
            5: "lost",  # terminal
            6: "staging",
        }

        state = states[status.state]
        logging.info("Task %s is in state %d", status.task_id.value, status.state)

        jobstep_id = self.taskJobStepMapping.get(status.task_id.value)

        if status.state == mesos_pb2.TASK_FINISHED:
            self.tasksFinished += 1

            self.taskJobStepMapping.pop(status.task_id.value, None)

        def api_request(url, body):
            full_url = self.api_url + url
            try:
                req = urllib2.Request(
                    full_url, json.dumps(body),
                    {'Content-Type': 'application/json'})
                urllib2.urlopen(req).read()
            except Exception:
                logging.exception("Error POSTing status update to service at %s",
                                  full_url)

        if not jobstep_id:
            # TODO(dcramer): how does this happen?
            logging.error("Task %s is missing JobStep ID", status.task_id.value)
            return

        # TODO(dcramer): when can we actually properly do deallocation?
        # Relying on the lxc-wrapper to mark things as in_progress at least
        # allows us to have a best-effort
        if state == 'finished':
            api_request("/jobsteps/%s/" % jobstep_id, {"status": "finished"})
        elif state in ('killed', 'lost', 'failed'):
            # Jobsteps are only intended to be executed once and should only exit non-zero or be
            # lost/killed by infrastructural issues, so we don't attempt to reschedule, and we mark
            # this down as an infrastructural failure. Note that this state may not mean that the
            # Jobstep will necessarily stop executing, but it means that the results will be
            # considered immediately invalid.
            logging.warn('Task %s %s: %s', jobstep_id, state, status.message)

            api_request(
                url='/jobsteps/%s/logappend/' % jobstep_id,
                body={
                    'text': '==> Scheduler marked task as %s (will NOT be retried):\n\n%s' % (
                        state, status.message),
                    'source': 'console',
                }
            )

            api_request("/jobsteps/%s/" % jobstep_id, {"status": "finished", "result": "infra_failed"})

    def frameworkMessage(self, driver, executorId, slaveId, message):
        """
          Invoked when an executor sends a message. These messages are best
          effort; do not expect a framework message to be retransmitted in any
          reliable fashion.
        """
        logging.info("Received message: %s", repr(str(message)))

    def slaveLost(self, driver, slaveId):
        """
          Invoked when a slave has been determined unreachable (e.g., machine
          failure, network partition.) Most frameworks will need to reschedule
          any tasks launched on this slave on a new slave.
        """
        logging.warn("Slave lost: %s", slaveId.value)

    def executorLost(self, driver, executorId, slaveId, status):
        """
          Invoked when an executor has exited/terminated. Note that any tasks
          running will have TASK_LOST status updates automatically generated.
        """
        logging.warn("Executor %s lost on slave %s", executorId.value, slaveId.value)

    def error(self, driver, message):
        """
          Invoked when there is an unrecoverable error in the scheduler or
          scheduler driver.  The driver will be aborted BEFORE invoking this
          callback.
        """
        logging.error("Error from Mesos: %s", message)


def main(api_url, mesos_master, user, config_dir):
    executor = mesos_pb2.ExecutorInfo()
    executor.executor_id.value = "default"
    executor.command.value = os.path.abspath("./executor.py")
    executor.name = "Changes Executor"
    executor.source = "changes"

    framework = mesos_pb2.FrameworkInfo()
    framework.user = user
    framework.name = "Changes Scheduler"
    framework.principal = "changes"

    scheduler = ChangesScheduler(executor, api_url, config_dir)

    driver = MesosSchedulerDriver(
        scheduler,
        framework,
        mesos_master)

    def handle_interrupt(signal, frame):
        logging.info("Received interrupt, shutting down")
        scheduler.shuttingDown.set()
        while driver.activeTasks > 0:
            logging.info("Waiting for %d tasks to finish running", driver.activeTasks)
            sleep(5)
        driver.stop()

    signal.signal(signal.SIGINT, handle_interrupt)

    status = 0 if driver.run() == mesos_pb2.DRIVER_STOPPED else 1

    # Ensure that the driver process terminates.
    driver.stop()

    sys.exit(status)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Mesos HTTP Proxy')

    parser.add_argument('--api-url', required=True, help='URL root of Changes API, including scheme. (e.g. http://localhost:5000/api/0/)')
    parser.add_argument('--mesos-master', default='127.0.1.1:5050', help='Location of Mesos master server. (e.g. 127.0.1.1:5050)')
    parser.add_argument('--user', default='root', help="User to run tasks as")
    parser.add_argument('--log-level', default='info', help="Level to log at. (e.g. info)")
    parser.add_argument('--config-dir', default=DEFAULT_CONFIG_DIR, help='Configuration directory')

    args = parser.parse_args(sys.argv[1:])
    logging.basicConfig(level=getattr(logging, args.log_level.upper()))
    install_sentry_logger()

    try:
        main(args.api_url, args.mesos_master, args.user, args.config_dir)
    except Exception as e:
        logging.exception(unicode(e))
        raise
